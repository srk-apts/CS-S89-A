{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S89A DL for NLP\n",
    "## `Assignment 01`    \t\n",
    "## Handed out: 06/24/2019                             \n",
    "## Due by 4:00 PM EST on Tuesday, 07/02/2019\n",
    "## Submitted by: Saurabh Kulkarni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTRUCTION: \n",
    "\n",
    "Please, describe every step of your work and present all intermediate and final results in a Word document. If you know how, please be free to organize your submission in one Jupyter notebook.  Please, copy-past text (ASCII) version of all essential commands and snippets of results into the Word document with explanations of the purpose of those commands. We cannot retype text that is in JPG images. Please, always submit a separate copy of the original, working scripts and/or class files you used. Sometimes we need to run your code and retyping is too costly. Please include in your MS Word document all the relevant portions of the console output or output files. PLEASE DO NOT EMBED files into your MS Word document. For issues and comments visit the class Piazza site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import r2_score\n",
    "import collections\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 (25%).\n",
    "Use the text of the Universal Declaration of Human Rights (UDHR). Create a table for 4 languages of your choice. Use that table to collect statistics about those languages. Place in that table the number of words in UDHR in each language, number of unique words, average length of words, number of sentences contained in UDHR and average number of words per sentence. You do not have to populate the table from your code. You may, but you may also determine individual values separately and enter them in the table manually.  Create a distribution of sentence lengths for all four language. Distribution of sentence lengths presents the number of sentences of varying length. Plot those (non-cumulative) distributions for all four languages using one diagram. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import udhr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abkhaz-Cyrillic+Abkh',\n",
       " 'Abkhaz-UTF8',\n",
       " 'Achehnese-Latin1',\n",
       " 'Achuar-Shiwiar-Latin1',\n",
       " 'Adja-UTF8',\n",
       " 'Afaan_Oromo_Oromiffa-Latin1',\n",
       " 'Afrikaans-Latin1',\n",
       " 'Aguaruna-Latin1',\n",
       " 'Akuapem_Twi-UTF8',\n",
       " 'Albanian_Shqip-Latin1',\n",
       " 'Amahuaca',\n",
       " 'Amahuaca-Latin1',\n",
       " 'Amarakaeri-Latin1',\n",
       " 'Amuesha-Yanesha-UTF8',\n",
       " 'Arabela-Latin1',\n",
       " 'Arabic_Alarabia-Arabic',\n",
       " 'Asante-UTF8',\n",
       " 'Ashaninca-Latin1',\n",
       " 'Asheninca-Latin1',\n",
       " 'Asturian_Bable-Latin1',\n",
       " 'Aymara-Latin1',\n",
       " 'Balinese-Latin1',\n",
       " 'Bambara-UTF8',\n",
       " 'Baoule-UTF8',\n",
       " 'Basque_Euskara-Latin1',\n",
       " 'Batonu_Bariba-UTF8',\n",
       " 'Belorus_Belaruski-Cyrillic',\n",
       " 'Belorus_Belaruski-UTF8',\n",
       " 'Bemba-Latin1',\n",
       " 'Bengali-UTF8',\n",
       " 'Beti-UTF8',\n",
       " 'Bichelamar-Latin1',\n",
       " 'Bikol_Bicolano-Latin1',\n",
       " 'Bora-Latin1',\n",
       " 'Bosnian_Bosanski-Cyrillic',\n",
       " 'Bosnian_Bosanski-Latin2',\n",
       " 'Bosnian_Bosanski-UTF8',\n",
       " 'Breton-Latin1',\n",
       " 'Bugisnese-Latin1',\n",
       " 'Bulgarian_Balgarski-Cyrillic',\n",
       " 'Bulgarian_Balgarski-UTF8',\n",
       " 'Cakchiquel-Latin1',\n",
       " 'Campa_Pajonalino-Latin1',\n",
       " 'Candoshi-Shapra-Latin1',\n",
       " 'Caquinte-Latin1',\n",
       " 'Cashibo-Cacataibo-Latin1',\n",
       " 'Cashinahua-Latin1',\n",
       " 'Catalan-Latin1',\n",
       " 'Catalan_Catala-Latin1',\n",
       " 'Cebuano-Latin1',\n",
       " 'Chamorro-Latin1',\n",
       " 'Chayahuita-Latin1',\n",
       " 'Chechewa_Nyanja-Latin1',\n",
       " 'Chickasaw-Latin1',\n",
       " 'Chinanteco-Ajitlan-Latin1',\n",
       " 'Chinanteco-UTF8',\n",
       " 'Chinese_Mandarin-GB2312',\n",
       " 'Chuuk_Trukese-Latin1',\n",
       " 'Cokwe-Latin1',\n",
       " 'Corsican-Latin1',\n",
       " 'Croatian_Hrvatski-Latin2',\n",
       " 'Czech-Latin2',\n",
       " 'Czech-UTF8',\n",
       " 'Czech_Cesky-Latin2',\n",
       " 'Czech_Cesky-UTF8',\n",
       " 'Dagaare-UTF8',\n",
       " 'Dagbani-UTF8',\n",
       " 'Dangme-UTF8',\n",
       " 'Danish_Dansk-Latin1',\n",
       " 'Dendi-UTF8',\n",
       " 'Ditammari-UTF8',\n",
       " 'Dutch_Nederlands-Latin1',\n",
       " 'Edo-Latin1',\n",
       " 'English-Latin1',\n",
       " 'Esperanto-UTF8',\n",
       " 'Estonian_Eesti-Latin1',\n",
       " 'Ewe_Eve-UTF8',\n",
       " 'Fante-UTF8',\n",
       " 'Faroese-Latin1',\n",
       " 'Farsi_Persian-UTF8',\n",
       " 'Farsi_Persian-v2-UTF8',\n",
       " 'Fijian-Latin1',\n",
       " 'Filipino_Tagalog-Latin1',\n",
       " 'Finnish_Suomi-Latin1',\n",
       " 'Fon-UTF8',\n",
       " 'French_Francais-Latin1',\n",
       " 'Frisian-Latin1',\n",
       " 'Friulian_Friulano-Latin1',\n",
       " 'Ga-UTF8',\n",
       " 'Gagauz_Gagauzi-UTF8',\n",
       " 'Galician_Galego-Latin1',\n",
       " 'Garifuna_Garifuna-Latin1',\n",
       " 'German_Deutsch-Latin1',\n",
       " 'Gonja-UTF8',\n",
       " 'Greek_Ellinika-Greek',\n",
       " 'Greek_Ellinika-UTF8',\n",
       " 'Greenlandic_Inuktikut-Latin1',\n",
       " 'Guarani-Latin1',\n",
       " 'Guen_Mina-UTF8',\n",
       " 'HaitianCreole_Kreyol-Latin1',\n",
       " 'HaitianCreole_Popular-Latin1',\n",
       " 'Hani-Latin1',\n",
       " 'Hausa_Haoussa-Latin1',\n",
       " 'Hawaiian-UTF8',\n",
       " 'Hebrew_Ivrit-Hebrew',\n",
       " 'Hebrew_Ivrit-UTF8',\n",
       " 'Hiligaynon-Latin1',\n",
       " 'Hindi-UTF8',\n",
       " 'Hindi_web-UTF8',\n",
       " 'Hmong_Miao-Sichuan-Guizhou-Yunnan-Latin1',\n",
       " 'Hmong_Miao-SouthernEast-Guizhou-Latin1',\n",
       " 'Hmong_Miao_Northern-East-Guizhou-Latin1',\n",
       " 'Hrvatski_Croatian-Latin2',\n",
       " 'Huasteco-Latin1',\n",
       " 'Huitoto_Murui-Latin1',\n",
       " 'Hungarian_Magyar-Latin1',\n",
       " 'Hungarian_Magyar-Latin2',\n",
       " 'Hungarian_Magyar-UTF8',\n",
       " 'Ibibio_Efik-Latin1',\n",
       " 'Icelandic_Yslenska-Latin1',\n",
       " 'Ido-Latin1',\n",
       " 'Igbo-UTF8',\n",
       " 'Iloko_Ilocano-Latin1',\n",
       " 'Indonesian-Latin1',\n",
       " 'Interlingua-Latin1',\n",
       " 'Inuktikut_Greenlandic-Latin1',\n",
       " 'IrishGaelic_Gaeilge-Latin1',\n",
       " 'Italian-Latin1',\n",
       " 'Italian_Italiano-Latin1',\n",
       " 'Japanese_Nihongo-EUC',\n",
       " 'Japanese_Nihongo-SJIS',\n",
       " 'Japanese_Nihongo-UTF8',\n",
       " 'Javanese-Latin1',\n",
       " 'Jola-Fogny_Diola-UTF8',\n",
       " 'Kabye-UTF8',\n",
       " 'Kannada-UTF8',\n",
       " 'Kaonde-Latin1',\n",
       " 'Kapampangan-Latin1',\n",
       " 'Kasem-UTF8',\n",
       " 'Kazakh-Cyrillic',\n",
       " 'Kazakh-UTF8',\n",
       " 'Kiche_Quiche-Latin1',\n",
       " 'Kicongo-Latin1',\n",
       " 'Kimbundu_Mbundu-Latin1',\n",
       " 'Kinyamwezi_Nyamwezi-Latin1',\n",
       " 'Kinyarwanda-Latin1',\n",
       " 'Kituba-Latin1',\n",
       " 'Korean_Hankuko-UTF8',\n",
       " 'Kpelewo-UTF8',\n",
       " 'Krio-UTF8',\n",
       " 'Kurdish-UTF8',\n",
       " 'Lamnso_Lam-nso-UTF8',\n",
       " 'Latin_Latina-Latin1',\n",
       " 'Latin_Latina-v2-Latin1',\n",
       " 'Latvian-Latin1',\n",
       " 'Limba-UTF8',\n",
       " 'Lingala-Latin1',\n",
       " 'Lithuanian_Lietuviskai-Baltic',\n",
       " 'Lozi-Latin1',\n",
       " 'Luba-Kasai_Tshiluba-Latin1',\n",
       " 'Luganda_Ganda-Latin1',\n",
       " 'Lunda_Chokwe-lunda-Latin1',\n",
       " 'Luvale-Latin1',\n",
       " 'Luxembourgish_Letzebuergeusch-Latin1',\n",
       " 'Macedonian-UTF8',\n",
       " 'Madurese-Latin1',\n",
       " 'Makonde-Latin1',\n",
       " 'Malagasy-Latin1',\n",
       " 'Malay_BahasaMelayu-Latin1',\n",
       " 'Maltese-UTF8',\n",
       " 'Mam-Latin1',\n",
       " 'Maninka-UTF8',\n",
       " 'Maori-Latin1',\n",
       " 'Mapudungun_Mapuzgun-Latin1',\n",
       " 'Mapudungun_Mapuzgun-UTF8',\n",
       " 'Marshallese-Latin1',\n",
       " 'Matses-Latin1',\n",
       " 'Mayan_Yucateco-Latin1',\n",
       " 'Mazahua_Jnatrjo-UTF8',\n",
       " 'Mazateco-Latin1',\n",
       " 'Mende-UTF8',\n",
       " 'Mikmaq_Micmac-Mikmaq-Latin1',\n",
       " 'Minangkabau-Latin1',\n",
       " 'Miskito_Miskito-Latin1',\n",
       " 'Mixteco-Latin1',\n",
       " 'Mongolian_Khalkha-Cyrillic',\n",
       " 'Mongolian_Khalkha-UTF8',\n",
       " 'Moore_More-UTF8',\n",
       " 'Nahuatl-Latin1',\n",
       " 'Ndebele-Latin1',\n",
       " 'Nepali-UTF8',\n",
       " 'Ngangela_Nyemba-Latin1',\n",
       " 'NigerianPidginEnglish-Latin1',\n",
       " 'Nomatsiguenga-Latin1',\n",
       " 'NorthernSotho_Pedi-Sepedi-Latin1',\n",
       " 'Norwegian-Latin1',\n",
       " 'Norwegian_Norsk-Bokmal-Latin1',\n",
       " 'Norwegian_Norsk-Nynorsk-Latin1',\n",
       " 'Nyanja_Chechewa-Latin1',\n",
       " 'Nyanja_Chinyanja-Latin1',\n",
       " 'Nzema-UTF8',\n",
       " 'OccitanAuvergnat-Latin1',\n",
       " 'OccitanLanguedocien-Latin1',\n",
       " 'Oromiffa_AfaanOromo-Latin1',\n",
       " 'Osetin_Ossetian-UTF8',\n",
       " 'Oshiwambo_Ndonga-Latin1',\n",
       " 'Otomi_Nahnu-Latin1',\n",
       " 'Paez-Latin1',\n",
       " 'Palauan-Latin1',\n",
       " 'Peuhl-UTF8',\n",
       " 'Picard-Latin1',\n",
       " 'Pipil-Latin1',\n",
       " 'Polish-Latin2',\n",
       " 'Polish_Polski-Latin2',\n",
       " 'Ponapean-Latin1',\n",
       " 'Portuguese_Portugues-Latin1',\n",
       " 'Pulaar-UTF8',\n",
       " 'Punjabi_Panjabi-UTF8',\n",
       " 'Purhepecha-UTF8',\n",
       " 'Qechi_Kekchi-Latin1',\n",
       " 'Quechua-Latin1',\n",
       " 'Quichua-Latin1',\n",
       " 'Rarotongan_MaoriCookIslands-Latin1',\n",
       " 'Rhaeto-Romance_Rumantsch-Latin1',\n",
       " 'Romani-Latin1',\n",
       " 'Romani-UTF8',\n",
       " 'Romanian-Latin2',\n",
       " 'Romanian_Romana-Latin2',\n",
       " 'Rukonzo_Konjo-Latin1',\n",
       " 'Rundi_Kirundi-Latin1',\n",
       " 'Runyankore-rukiga_Nkore-kiga-Latin1',\n",
       " 'Russian-Cyrillic',\n",
       " 'Russian-UTF8',\n",
       " 'Russian_Russky-Cyrillic',\n",
       " 'Russian_Russky-UTF8',\n",
       " 'Sami_Lappish-UTF8',\n",
       " 'Sammarinese-Latin1',\n",
       " 'Samoan-Latin1',\n",
       " 'Sango_Sangho-Latin1',\n",
       " 'Sanskrit-UTF8',\n",
       " 'Saraiki-UTF8',\n",
       " 'Sardinian-Latin1',\n",
       " 'ScottishGaelic_GaidhligAlbanach-Latin1',\n",
       " 'Seereer-UTF8',\n",
       " 'Serbian_Srpski-Cyrillic',\n",
       " 'Serbian_Srpski-Latin2',\n",
       " 'Serbian_Srpski-UTF8',\n",
       " 'Sharanahua-Latin1',\n",
       " 'Shipibo-Conibo-Latin1',\n",
       " 'Shona-Latin1',\n",
       " 'Sinhala-UTF8',\n",
       " 'Siswati-Latin1',\n",
       " 'Slovak-Latin2',\n",
       " 'Slovak_Slovencina-Latin2',\n",
       " 'Slovenian_Slovenscina-Latin2',\n",
       " 'SolomonsPidgin_Pijin-Latin1',\n",
       " 'Somali-Latin1',\n",
       " 'Soninke_Soninkanxaane-UTF8',\n",
       " 'Sorbian-Latin2',\n",
       " 'SouthernSotho_Sotho-Sesotho-Sutu-Sesutu-Latin1',\n",
       " 'Spanish-Latin1',\n",
       " 'Spanish_Espanol-Latin1',\n",
       " 'Sukuma-Latin1',\n",
       " 'Sundanese-Latin1',\n",
       " 'Sussu_Soussou-Sosso-Soso-Susu-UTF8',\n",
       " 'Swaheli-Latin1',\n",
       " 'Swahili_Kiswahili-Latin1',\n",
       " 'Swedish_Svenska-Latin1',\n",
       " 'Tahitian-UTF8',\n",
       " 'Tenek_Huasteco-Latin1',\n",
       " 'Tetum-Latin1',\n",
       " 'Themne_Temne-UTF8',\n",
       " 'Tiv-Latin1',\n",
       " 'Toba-UTF8',\n",
       " 'Tojol-abal-Latin1',\n",
       " 'TokPisin-Latin1',\n",
       " 'Tonga-Latin1',\n",
       " 'Tongan_Tonga-Latin1',\n",
       " 'Totonaco-Latin1',\n",
       " 'Trukese_Chuuk-Latin1',\n",
       " 'Turkish_Turkce-Turkish',\n",
       " 'Turkish_Turkce-UTF8',\n",
       " 'Tzeltal-Latin1',\n",
       " 'Tzotzil-Latin1',\n",
       " 'Uighur_Uyghur-Latin1',\n",
       " 'Uighur_Uyghur-UTF8',\n",
       " 'Ukrainian-Cyrillic',\n",
       " 'Ukrainian-UTF8',\n",
       " 'Umbundu-Latin1',\n",
       " 'Urarina-Latin1',\n",
       " 'Uzbek-Latin1',\n",
       " 'Vietnamese-ALRN-UTF8',\n",
       " 'Vietnamese-UTF8',\n",
       " 'Vlach-Latin1',\n",
       " 'Walloon_Wallon-Latin1',\n",
       " 'Wama-UTF8',\n",
       " 'Waray-Latin1',\n",
       " 'Wayuu-Latin1',\n",
       " 'Welsh_Cymraeg-Latin1',\n",
       " 'WesternSotho_Tswana-Setswana-Latin1',\n",
       " 'Wolof-Latin1',\n",
       " 'Xhosa-Latin1',\n",
       " 'Yagua-Latin1',\n",
       " 'Yao-Latin1',\n",
       " 'Yapese-Latin1',\n",
       " 'Yoruba-UTF8',\n",
       " 'Zapoteco-Latin1',\n",
       " 'Zapoteco-SanLucasQuiavini-Latin1',\n",
       " 'Zhuang-Latin1',\n",
       " 'Zulu-Latin1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udhr.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = ['English-Latin1', 'Hindi-UTF8', 'Kannada-UTF8', 'Hebrew_Ivrit-Hebrew']\n",
    "udhr_stats_dict = {}\n",
    "sents_len_dict = {}\n",
    "\n",
    "for l in lang:\n",
    "    \n",
    "    udhr_words = udhr.words(l)\n",
    "    n_words = len(udhr_words)\n",
    "    n_unique = len(np.unique(udhr_words))\n",
    "\n",
    "    word_len = []\n",
    "    for w in udhr_words:\n",
    "        word_len.append(len(w))\n",
    "\n",
    "    avg_word_len = np.mean(word_len)\n",
    "\n",
    "    udhr_sents = udhr.sents(l)\n",
    "    n_sents = len(udhr_sents)\n",
    "\n",
    "    sent_len = []\n",
    "    for s in udhr_sents:\n",
    "        sent_len.append(len(s))\n",
    "        \n",
    "    sents_len_dict[l] = sent_len\n",
    "\n",
    "    avg_sent_len = np.mean(sent_len)\n",
    "\n",
    "    udhr_stats_dict[l] = [n_words, n_unique, avg_word_len, n_sents, avg_sent_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English-Latin1</th>\n",
       "      <th>Hindi-UTF8</th>\n",
       "      <th>Kannada-UTF8</th>\n",
       "      <th>Hebrew_Ivrit-Hebrew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total Words</th>\n",
       "      <td>1781.00000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2529.000000</td>\n",
       "      <td>1530.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># Unique Words</th>\n",
       "      <td>533.00000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>782.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg. Word Length</th>\n",
       "      <td>4.64402</td>\n",
       "      <td>1.236529</td>\n",
       "      <td>1.271649</td>\n",
       "      <td>3.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># Sentences</th>\n",
       "      <td>67.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg. Sentence Length</th>\n",
       "      <td>26.58209</td>\n",
       "      <td>315.500000</td>\n",
       "      <td>81.580645</td>\n",
       "      <td>21.549296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      English-Latin1   Hindi-UTF8  Kannada-UTF8  \\\n",
       "Total Words               1781.00000  2524.000000   2529.000000   \n",
       "# Unique Words             533.00000   224.000000    278.000000   \n",
       "Avg. Word Length             4.64402     1.236529      1.271649   \n",
       "# Sentences                 67.00000     8.000000     31.000000   \n",
       "Avg. Sentence Length        26.58209   315.500000     81.580645   \n",
       "\n",
       "                      Hebrew_Ivrit-Hebrew  \n",
       "Total Words                   1530.000000  \n",
       "# Unique Words                 782.000000  \n",
       "Avg. Word Length                 3.960784  \n",
       "# Sentences                     71.000000  \n",
       "Avg. Sentence Length            21.549296  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind = ['Total Words', '# Unique Words', 'Avg. Word Length', '# Sentences', 'Avg. Sentence Length']\n",
    "udhr_stats_df = pd.DataFrame(udhr_stats_dict, index=df_ind)\n",
    "udhr_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fba3dbf5ba8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,7))\n",
    "for l in lang:\n",
    "    ax.hist(sents_len_dict[l], label=l)\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 (25%). \n",
    "Identify 10 most frequently used words longer than 7 characters in the entire corpus of Inaugural Addresses. Do not identify 10 words for every speech but rather 10 words for the entire corpus. Which among those words has the largest number of synonyms? List all synonyms for those 10 words. Which one of those 10 words has the largest number of hyponyms? List all hyponyms of those 10 most frequently used “long” words. The purpose of this problem is to familiarize you with WordNet and concepts of synonyms and hyponyms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to /home/srk-\n",
      "[nltk_data]     apts/nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('inaugural')\n",
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaugural_fileids = inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for f in inaugural_fileids:\n",
    "    words_f = inaugural.words(f)\n",
    "    for w in words_f:\n",
    "        if len(w)>7:\n",
    "            words.append(w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = collections.Counter(words)\n",
    "top10_tuples = counter.most_common(10)\n",
    "unzipped = zip(*top10_tuples)\n",
    "top10 = list(list(unzipped)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "government 9\n",
      "citizens 1\n",
      "constitution 17\n",
      "american 3\n",
      "national 5\n",
      "congress 15\n",
      "interests 12\n",
      "political 1\n",
      "executive 3\n",
      "principles 4\n"
     ]
    }
   ],
   "source": [
    "for w in top10:\n",
    "    synonyms = []\n",
    "    for synset in wn.synsets(w):\n",
    "        synonyms = synonyms+synset.lemma_names()\n",
    "    syn_count = len(np.unique(synonyms))\n",
    "    print(w,syn_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in top10:\n",
    "    hyponyms = []\n",
    "    for synset in wn.synsets(w):\n",
    "        hyponyms = hyp_count+synset.lemma_names()\n",
    "    hyp_count = len(np.unique(hyponyms))\n",
    "    print(w,hyp_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3. \n",
    "Consider 100 points along the straight line in $(x,y)$ plane represented by the linear equation $y=0.3x+0.2$. Distribute those points along the line uniformly in the interval between -2.0 and 3.0. To the y coordinate of each point add a random normally distributed value with standard deviation of 1 and mean 0. You have created and artificial set of random measurements. Create a shallow neural network with one layer which will be able to predict y value corresponding to any x value in the above interval. Implement and train the network using Keras API. Report on the accuracy of your model. This is a rather trivial problem and you do not need neural networks to solve it. We are practicing Keras API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(low=-2.0, high=3.0, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = 0.3*x + 0.2 \n",
    "noise = np.random.normal(loc=0, scale=1, size=100)\n",
    "y = line+noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9001)\n",
    "mask = np.random.rand(100) < 0.7 \n",
    "x_train = x[mask]\n",
    "x_test = x[~mask]\n",
    "y_train = y[mask]\n",
    "y_test = y[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Dense(2, input_shape=(1,)))\n",
    "model.add(Dense(1, input_shape=(1,)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 36 samples\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.0574 - val_loss: 3.8524\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 90us/step - loss: 3.2282 - val_loss: 3.1716\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 149us/step - loss: 2.6307 - val_loss: 2.6859\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 113us/step - loss: 2.2207 - val_loss: 2.3368\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.8966 - val_loss: 2.0868\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.6762 - val_loss: 1.9111\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.5219 - val_loss: 1.7830\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.4092 - val_loss: 1.6905\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.3269 - val_loss: 1.6244\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.2685 - val_loss: 1.5758\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.2306 - val_loss: 1.5401\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1936 - val_loss: 1.5140\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.1724 - val_loss: 1.4941\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1536 - val_loss: 1.4792\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.1421 - val_loss: 1.4674\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.1335 - val_loss: 1.4586\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.1250 - val_loss: 1.4511\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.1184 - val_loss: 1.4451\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.1221 - val_loss: 1.4401\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1112 - val_loss: 1.4360\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1073 - val_loss: 1.4325\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.1038 - val_loss: 1.4294\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.1010 - val_loss: 1.4266\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.0998 - val_loss: 1.4241\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1004 - val_loss: 1.4219\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.1018 - val_loss: 1.4198\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.0972 - val_loss: 1.4179\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 191us/step - loss: 1.0978 - val_loss: 1.4165\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.0957 - val_loss: 1.4151\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.0959 - val_loss: 1.4135\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.0942 - val_loss: 1.4121\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.0981 - val_loss: 1.4111\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.0932 - val_loss: 1.4101\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.0957 - val_loss: 1.4091\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.0920 - val_loss: 1.4081\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.0914 - val_loss: 1.4073\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.0927 - val_loss: 1.4066\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.0935 - val_loss: 1.4057\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.0932 - val_loss: 1.4052\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.0911 - val_loss: 1.4046\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.0905 - val_loss: 1.4039\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.0906 - val_loss: 1.4034\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.0907 - val_loss: 1.4028\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.0908 - val_loss: 1.4022\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.0901 - val_loss: 1.4018\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.0909 - val_loss: 1.4012\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.0922 - val_loss: 1.4010\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 170us/step - loss: 1.0917 - val_loss: 1.4007\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.0910 - val_loss: 1.4005\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.0904 - val_loss: 1.4002\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 160us/step - loss: 1.0949 - val_loss: 1.3996\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.0913 - val_loss: 1.3994\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.0921 - val_loss: 1.3993\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.0932 - val_loss: 1.3988\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.0894 - val_loss: 1.3987\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.0925 - val_loss: 1.3986\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.0908 - val_loss: 1.3983\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.0929 - val_loss: 1.3982\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.0949 - val_loss: 1.3982\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.0918 - val_loss: 1.3983\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.0903 - val_loss: 1.3979\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.0900 - val_loss: 1.3977\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.0910 - val_loss: 1.3973\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.0899 - val_loss: 1.3973\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.0923 - val_loss: 1.3970\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.0921 - val_loss: 1.3972\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.0924 - val_loss: 1.3968\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.0957 - val_loss: 1.3968\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.0912 - val_loss: 1.3967\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.0917 - val_loss: 1.3968\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.0937 - val_loss: 1.3965\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.0941 - val_loss: 1.3965\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.0936 - val_loss: 1.3963\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.0958 - val_loss: 1.3962\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.0922 - val_loss: 1.3960\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.0978 - val_loss: 1.3963\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.0912 - val_loss: 1.3965\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.0916 - val_loss: 1.3962\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.0914 - val_loss: 1.3964\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.0953 - val_loss: 1.3961\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 162us/step - loss: 1.0903 - val_loss: 1.3961\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.0921 - val_loss: 1.3963\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.0904 - val_loss: 1.3964\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.0923 - val_loss: 1.3961\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.0910 - val_loss: 1.3961\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.0908 - val_loss: 1.3959\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.0895 - val_loss: 1.3960\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.0916 - val_loss: 1.3960\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.0897 - val_loss: 1.3959\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.0926 - val_loss: 1.3958\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.0947 - val_loss: 1.3961\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.0908 - val_loss: 1.3962\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 165us/step - loss: 1.0905 - val_loss: 1.3960\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.0897 - val_loss: 1.3960\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.0917 - val_loss: 1.3962\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.0901 - val_loss: 1.3961\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.0986 - val_loss: 1.3955\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.0916 - val_loss: 1.3956\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.0942 - val_loss: 1.3955\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.0912 - val_loss: 1.3957\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=16,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=[x_test, y_test]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fba14644ba8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0011379086751754919"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.  \n",
    "Consider three points in (x,y) plane with coordinates (-2,0), (0,1.7) and (2.1,0). Around each of those three centers create a cloud of 100 randomly generated points. For the radial distance of any one of those points from its center use a random normal distribution.  For the angular coordinate of any one of “cloud” points use the uniform distribution. Once you have generated all three sets of cloud points plot them in the same diagram using three different colors. There should exist some overlap between the clouds. Create a two-layer neural network. Use Keras API. Fit a model that could predict whether a randomly generated point in the plane belongs to cloud 1, centered around (-2,0), cloud 2, centered around (0,1.7) or cloud 3, centered around (2.1,0). You can make that prediction in a much simpler way, however, we are practicing Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
