{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S89A Deep Learning for NLP\n",
    "## `Assignment 01`    \t\n",
    "## Handed out: 06/24/2019                             \n",
    "## Due by 11:59 PM EST on Tuesday, 07/02/2019\n",
    "## Submitted by: Saurabh Kulkarni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTRUCTION: \n",
    "\n",
    "Please, describe every step of your work and present all intermediate and final results in a Word document. If you know how, please be free to organize your submission in one Jupyter notebook.  Please, copy-past text (ASCII) version of all essential commands and snippets of results into the Word document with explanations of the purpose of those commands. We cannot retype text that is in JPG images. Please, always submit a separate copy of the original, working scripts and/or class files you used. Sometimes we need to run your code and retyping is too costly. Please include in your MS Word document all the relevant portions of the console output or output files. PLEASE DO NOT EMBED files into your MS Word document. For issues and comments visit the class Piazza site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import r2_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "from nltk.corpus import wordnet as wn\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 (25%).\n",
    "Use the text of the Universal Declaration of Human Rights (UDHR). Create a table for 4 languages of your choice. Use that table to collect statistics about those languages. Place in that table the number of words in UDHR in each language, number of unique words, average length of words, number of sentences contained in UDHR and average number of words per sentence. You do not have to populate the table from your code. You may, but you may also determine individual values separately and enter them in the table manually.  Create a distribution of sentence lengths for all four language. Distribution of sentence lengths presents the number of sentences of varying length. Plot those (non-cumulative) distributions for all four languages using one diagram. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Download the required nltk packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package udhr to\n",
      "[nltk_data]     C:\\Users\\A0687514\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package udhr is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\A0687514\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('udhr')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import udhr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abkhaz-Cyrillic+Abkh',\n",
       " 'Abkhaz-UTF8',\n",
       " 'Achehnese-Latin1',\n",
       " 'Achuar-Shiwiar-Latin1',\n",
       " 'Adja-UTF8',\n",
       " 'Afaan_Oromo_Oromiffa-Latin1',\n",
       " 'Afrikaans-Latin1',\n",
       " 'Aguaruna-Latin1',\n",
       " 'Akuapem_Twi-UTF8',\n",
       " 'Albanian_Shqip-Latin1',\n",
       " 'Amahuaca',\n",
       " 'Amahuaca-Latin1',\n",
       " 'Amarakaeri-Latin1',\n",
       " 'Amuesha-Yanesha-UTF8',\n",
       " 'Arabela-Latin1',\n",
       " 'Arabic_Alarabia-Arabic',\n",
       " 'Asante-UTF8',\n",
       " 'Ashaninca-Latin1',\n",
       " 'Asheninca-Latin1',\n",
       " 'Asturian_Bable-Latin1',\n",
       " 'Aymara-Latin1',\n",
       " 'Balinese-Latin1',\n",
       " 'Bambara-UTF8',\n",
       " 'Baoule-UTF8',\n",
       " 'Basque_Euskara-Latin1',\n",
       " 'Batonu_Bariba-UTF8',\n",
       " 'Belorus_Belaruski-Cyrillic',\n",
       " 'Belorus_Belaruski-UTF8',\n",
       " 'Bemba-Latin1',\n",
       " 'Bengali-UTF8',\n",
       " 'Beti-UTF8',\n",
       " 'Bichelamar-Latin1',\n",
       " 'Bikol_Bicolano-Latin1',\n",
       " 'Bora-Latin1',\n",
       " 'Bosnian_Bosanski-Cyrillic',\n",
       " 'Bosnian_Bosanski-Latin2',\n",
       " 'Bosnian_Bosanski-UTF8',\n",
       " 'Breton-Latin1',\n",
       " 'Bugisnese-Latin1',\n",
       " 'Bulgarian_Balgarski-Cyrillic',\n",
       " 'Bulgarian_Balgarski-UTF8',\n",
       " 'Cakchiquel-Latin1',\n",
       " 'Campa_Pajonalino-Latin1',\n",
       " 'Candoshi-Shapra-Latin1',\n",
       " 'Caquinte-Latin1',\n",
       " 'Cashibo-Cacataibo-Latin1',\n",
       " 'Cashinahua-Latin1',\n",
       " 'Catalan-Latin1',\n",
       " 'Catalan_Catala-Latin1',\n",
       " 'Cebuano-Latin1',\n",
       " 'Chamorro-Latin1',\n",
       " 'Chayahuita-Latin1',\n",
       " 'Chechewa_Nyanja-Latin1',\n",
       " 'Chickasaw-Latin1',\n",
       " 'Chinanteco-Ajitlan-Latin1',\n",
       " 'Chinanteco-UTF8',\n",
       " 'Chinese_Mandarin-GB2312',\n",
       " 'Chuuk_Trukese-Latin1',\n",
       " 'Cokwe-Latin1',\n",
       " 'Corsican-Latin1',\n",
       " 'Croatian_Hrvatski-Latin2',\n",
       " 'Czech-Latin2',\n",
       " 'Czech-UTF8',\n",
       " 'Czech_Cesky-Latin2',\n",
       " 'Czech_Cesky-UTF8',\n",
       " 'Dagaare-UTF8',\n",
       " 'Dagbani-UTF8',\n",
       " 'Dangme-UTF8',\n",
       " 'Danish_Dansk-Latin1',\n",
       " 'Dendi-UTF8',\n",
       " 'Ditammari-UTF8',\n",
       " 'Dutch_Nederlands-Latin1',\n",
       " 'Edo-Latin1',\n",
       " 'English-Latin1',\n",
       " 'Esperanto-UTF8',\n",
       " 'Estonian_Eesti-Latin1',\n",
       " 'Ewe_Eve-UTF8',\n",
       " 'Fante-UTF8',\n",
       " 'Faroese-Latin1',\n",
       " 'Farsi_Persian-UTF8',\n",
       " 'Farsi_Persian-v2-UTF8',\n",
       " 'Fijian-Latin1',\n",
       " 'Filipino_Tagalog-Latin1',\n",
       " 'Finnish_Suomi-Latin1',\n",
       " 'Fon-UTF8',\n",
       " 'French_Francais-Latin1',\n",
       " 'Frisian-Latin1',\n",
       " 'Friulian_Friulano-Latin1',\n",
       " 'Ga-UTF8',\n",
       " 'Gagauz_Gagauzi-UTF8',\n",
       " 'Galician_Galego-Latin1',\n",
       " 'Garifuna_Garifuna-Latin1',\n",
       " 'German_Deutsch-Latin1',\n",
       " 'Gonja-UTF8',\n",
       " 'Greek_Ellinika-Greek',\n",
       " 'Greek_Ellinika-UTF8',\n",
       " 'Greenlandic_Inuktikut-Latin1',\n",
       " 'Guarani-Latin1',\n",
       " 'Guen_Mina-UTF8',\n",
       " 'HaitianCreole_Kreyol-Latin1',\n",
       " 'HaitianCreole_Popular-Latin1',\n",
       " 'Hani-Latin1',\n",
       " 'Hausa_Haoussa-Latin1',\n",
       " 'Hawaiian-UTF8',\n",
       " 'Hebrew_Ivrit-Hebrew',\n",
       " 'Hebrew_Ivrit-UTF8',\n",
       " 'Hiligaynon-Latin1',\n",
       " 'Hindi-UTF8',\n",
       " 'Hindi_web-UTF8',\n",
       " 'Hmong_Miao-Sichuan-Guizhou-Yunnan-Latin1',\n",
       " 'Hmong_Miao-SouthernEast-Guizhou-Latin1',\n",
       " 'Hmong_Miao_Northern-East-Guizhou-Latin1',\n",
       " 'Hrvatski_Croatian-Latin2',\n",
       " 'Huasteco-Latin1',\n",
       " 'Huitoto_Murui-Latin1',\n",
       " 'Hungarian_Magyar-Latin1',\n",
       " 'Hungarian_Magyar-Latin2',\n",
       " 'Hungarian_Magyar-UTF8',\n",
       " 'Ibibio_Efik-Latin1',\n",
       " 'Icelandic_Yslenska-Latin1',\n",
       " 'Ido-Latin1',\n",
       " 'Igbo-UTF8',\n",
       " 'Iloko_Ilocano-Latin1',\n",
       " 'Indonesian-Latin1',\n",
       " 'Interlingua-Latin1',\n",
       " 'Inuktikut_Greenlandic-Latin1',\n",
       " 'IrishGaelic_Gaeilge-Latin1',\n",
       " 'Italian-Latin1',\n",
       " 'Italian_Italiano-Latin1',\n",
       " 'Japanese_Nihongo-EUC',\n",
       " 'Japanese_Nihongo-SJIS',\n",
       " 'Japanese_Nihongo-UTF8',\n",
       " 'Javanese-Latin1',\n",
       " 'Jola-Fogny_Diola-UTF8',\n",
       " 'Kabye-UTF8',\n",
       " 'Kannada-UTF8',\n",
       " 'Kaonde-Latin1',\n",
       " 'Kapampangan-Latin1',\n",
       " 'Kasem-UTF8',\n",
       " 'Kazakh-Cyrillic',\n",
       " 'Kazakh-UTF8',\n",
       " 'Kiche_Quiche-Latin1',\n",
       " 'Kicongo-Latin1',\n",
       " 'Kimbundu_Mbundu-Latin1',\n",
       " 'Kinyamwezi_Nyamwezi-Latin1',\n",
       " 'Kinyarwanda-Latin1',\n",
       " 'Kituba-Latin1',\n",
       " 'Korean_Hankuko-UTF8',\n",
       " 'Kpelewo-UTF8',\n",
       " 'Krio-UTF8',\n",
       " 'Kurdish-UTF8',\n",
       " 'Lamnso_Lam-nso-UTF8',\n",
       " 'Latin_Latina-Latin1',\n",
       " 'Latin_Latina-v2-Latin1',\n",
       " 'Latvian-Latin1',\n",
       " 'Limba-UTF8',\n",
       " 'Lingala-Latin1',\n",
       " 'Lithuanian_Lietuviskai-Baltic',\n",
       " 'Lozi-Latin1',\n",
       " 'Luba-Kasai_Tshiluba-Latin1',\n",
       " 'Luganda_Ganda-Latin1',\n",
       " 'Lunda_Chokwe-lunda-Latin1',\n",
       " 'Luvale-Latin1',\n",
       " 'Luxembourgish_Letzebuergeusch-Latin1',\n",
       " 'Macedonian-UTF8',\n",
       " 'Madurese-Latin1',\n",
       " 'Makonde-Latin1',\n",
       " 'Malagasy-Latin1',\n",
       " 'Malay_BahasaMelayu-Latin1',\n",
       " 'Maltese-UTF8',\n",
       " 'Mam-Latin1',\n",
       " 'Maninka-UTF8',\n",
       " 'Maori-Latin1',\n",
       " 'Mapudungun_Mapuzgun-Latin1',\n",
       " 'Mapudungun_Mapuzgun-UTF8',\n",
       " 'Marshallese-Latin1',\n",
       " 'Matses-Latin1',\n",
       " 'Mayan_Yucateco-Latin1',\n",
       " 'Mazahua_Jnatrjo-UTF8',\n",
       " 'Mazateco-Latin1',\n",
       " 'Mende-UTF8',\n",
       " 'Mikmaq_Micmac-Mikmaq-Latin1',\n",
       " 'Minangkabau-Latin1',\n",
       " 'Miskito_Miskito-Latin1',\n",
       " 'Mixteco-Latin1',\n",
       " 'Mongolian_Khalkha-Cyrillic',\n",
       " 'Mongolian_Khalkha-UTF8',\n",
       " 'Moore_More-UTF8',\n",
       " 'Nahuatl-Latin1',\n",
       " 'Ndebele-Latin1',\n",
       " 'Nepali-UTF8',\n",
       " 'Ngangela_Nyemba-Latin1',\n",
       " 'NigerianPidginEnglish-Latin1',\n",
       " 'Nomatsiguenga-Latin1',\n",
       " 'NorthernSotho_Pedi-Sepedi-Latin1',\n",
       " 'Norwegian-Latin1',\n",
       " 'Norwegian_Norsk-Bokmal-Latin1',\n",
       " 'Norwegian_Norsk-Nynorsk-Latin1',\n",
       " 'Nyanja_Chechewa-Latin1',\n",
       " 'Nyanja_Chinyanja-Latin1',\n",
       " 'Nzema-UTF8',\n",
       " 'OccitanAuvergnat-Latin1',\n",
       " 'OccitanLanguedocien-Latin1',\n",
       " 'Oromiffa_AfaanOromo-Latin1',\n",
       " 'Osetin_Ossetian-UTF8',\n",
       " 'Oshiwambo_Ndonga-Latin1',\n",
       " 'Otomi_Nahnu-Latin1',\n",
       " 'Paez-Latin1',\n",
       " 'Palauan-Latin1',\n",
       " 'Peuhl-UTF8',\n",
       " 'Picard-Latin1',\n",
       " 'Pipil-Latin1',\n",
       " 'Polish-Latin2',\n",
       " 'Polish_Polski-Latin2',\n",
       " 'Ponapean-Latin1',\n",
       " 'Portuguese_Portugues-Latin1',\n",
       " 'Pulaar-UTF8',\n",
       " 'Punjabi_Panjabi-UTF8',\n",
       " 'Purhepecha-UTF8',\n",
       " 'Qechi_Kekchi-Latin1',\n",
       " 'Quechua-Latin1',\n",
       " 'Quichua-Latin1',\n",
       " 'Rarotongan_MaoriCookIslands-Latin1',\n",
       " 'Rhaeto-Romance_Rumantsch-Latin1',\n",
       " 'Romani-Latin1',\n",
       " 'Romani-UTF8',\n",
       " 'Romanian-Latin2',\n",
       " 'Romanian_Romana-Latin2',\n",
       " 'Rukonzo_Konjo-Latin1',\n",
       " 'Rundi_Kirundi-Latin1',\n",
       " 'Runyankore-rukiga_Nkore-kiga-Latin1',\n",
       " 'Russian-Cyrillic',\n",
       " 'Russian-UTF8',\n",
       " 'Russian_Russky-Cyrillic',\n",
       " 'Russian_Russky-UTF8',\n",
       " 'Sami_Lappish-UTF8',\n",
       " 'Sammarinese-Latin1',\n",
       " 'Samoan-Latin1',\n",
       " 'Sango_Sangho-Latin1',\n",
       " 'Sanskrit-UTF8',\n",
       " 'Saraiki-UTF8',\n",
       " 'Sardinian-Latin1',\n",
       " 'ScottishGaelic_GaidhligAlbanach-Latin1',\n",
       " 'Seereer-UTF8',\n",
       " 'Serbian_Srpski-Cyrillic',\n",
       " 'Serbian_Srpski-Latin2',\n",
       " 'Serbian_Srpski-UTF8',\n",
       " 'Sharanahua-Latin1',\n",
       " 'Shipibo-Conibo-Latin1',\n",
       " 'Shona-Latin1',\n",
       " 'Sinhala-UTF8',\n",
       " 'Siswati-Latin1',\n",
       " 'Slovak-Latin2',\n",
       " 'Slovak_Slovencina-Latin2',\n",
       " 'Slovenian_Slovenscina-Latin2',\n",
       " 'SolomonsPidgin_Pijin-Latin1',\n",
       " 'Somali-Latin1',\n",
       " 'Soninke_Soninkanxaane-UTF8',\n",
       " 'Sorbian-Latin2',\n",
       " 'SouthernSotho_Sotho-Sesotho-Sutu-Sesutu-Latin1',\n",
       " 'Spanish-Latin1',\n",
       " 'Spanish_Espanol-Latin1',\n",
       " 'Sukuma-Latin1',\n",
       " 'Sundanese-Latin1',\n",
       " 'Sussu_Soussou-Sosso-Soso-Susu-UTF8',\n",
       " 'Swaheli-Latin1',\n",
       " 'Swahili_Kiswahili-Latin1',\n",
       " 'Swedish_Svenska-Latin1',\n",
       " 'Tahitian-UTF8',\n",
       " 'Tenek_Huasteco-Latin1',\n",
       " 'Tetum-Latin1',\n",
       " 'Themne_Temne-UTF8',\n",
       " 'Tiv-Latin1',\n",
       " 'Toba-UTF8',\n",
       " 'Tojol-abal-Latin1',\n",
       " 'TokPisin-Latin1',\n",
       " 'Tonga-Latin1',\n",
       " 'Tongan_Tonga-Latin1',\n",
       " 'Totonaco-Latin1',\n",
       " 'Trukese_Chuuk-Latin1',\n",
       " 'Turkish_Turkce-Turkish',\n",
       " 'Turkish_Turkce-UTF8',\n",
       " 'Tzeltal-Latin1',\n",
       " 'Tzotzil-Latin1',\n",
       " 'Uighur_Uyghur-Latin1',\n",
       " 'Uighur_Uyghur-UTF8',\n",
       " 'Ukrainian-Cyrillic',\n",
       " 'Ukrainian-UTF8',\n",
       " 'Umbundu-Latin1',\n",
       " 'Urarina-Latin1',\n",
       " 'Uzbek-Latin1',\n",
       " 'Vietnamese-ALRN-UTF8',\n",
       " 'Vietnamese-UTF8',\n",
       " 'Vlach-Latin1',\n",
       " 'Walloon_Wallon-Latin1',\n",
       " 'Wama-UTF8',\n",
       " 'Waray-Latin1',\n",
       " 'Wayuu-Latin1',\n",
       " 'Welsh_Cymraeg-Latin1',\n",
       " 'WesternSotho_Tswana-Setswana-Latin1',\n",
       " 'Wolof-Latin1',\n",
       " 'Xhosa-Latin1',\n",
       " 'Yagua-Latin1',\n",
       " 'Yao-Latin1',\n",
       " 'Yapese-Latin1',\n",
       " 'Yoruba-UTF8',\n",
       " 'Zapoteco-Latin1',\n",
       " 'Zapoteco-SanLucasQuiavini-Latin1',\n",
       " 'Zhuang-Latin1',\n",
       " 'Zulu-Latin1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udhr.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Here we loop over four languages selected from the list `udhr.fileids()` and collect the statistics asked in the question. \n",
    "- `udhr.words()` and `udhr.sents()` gives us a list of all the words and sentences, respectively, present in UDHR.\n",
    "- The total number of words, unique words and number of sentences are counted by simply counting the number of items in the list.\n",
    "- We loop over all words and sentences and store word lengths and sentence lengths in a list. And then calculate the averages using these lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = ['English-Latin1', 'Hindi-UTF8', 'Kannada-UTF8', 'Hebrew_Ivrit-Hebrew']\n",
    "udhr_stats_dict = {}\n",
    "sents_len_dict = {}\n",
    "\n",
    "for l in lang:\n",
    "    \n",
    "    udhr_words = udhr.words(l)\n",
    "    n_words = len(udhr_words)\n",
    "    n_unique = len(np.unique(udhr_words))\n",
    "\n",
    "    word_len = []\n",
    "    for w in udhr_words:\n",
    "        word_len.append(len(w))\n",
    "\n",
    "    avg_word_len = np.mean(word_len)\n",
    "\n",
    "    udhr_sents = udhr.sents(l)\n",
    "    n_sents = len(udhr_sents)\n",
    "\n",
    "    sent_len = []\n",
    "    for s in udhr_sents:\n",
    "        sent_len.append(len(s))\n",
    "        \n",
    "    sents_len_dict[l] = sent_len\n",
    "\n",
    "    avg_sent_len = np.mean(sent_len)\n",
    "\n",
    "    udhr_stats_dict[l] = [n_words, n_unique, avg_word_len, n_sents, avg_sent_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Converting dictionary to data frame for better visual presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English-Latin1</th>\n",
       "      <th>Hindi-UTF8</th>\n",
       "      <th>Kannada-UTF8</th>\n",
       "      <th>Hebrew_Ivrit-Hebrew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total Words</th>\n",
       "      <td>1781.00000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2529.000000</td>\n",
       "      <td>1530.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># Unique Words</th>\n",
       "      <td>533.00000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>782.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg. Word Length</th>\n",
       "      <td>4.64402</td>\n",
       "      <td>1.236529</td>\n",
       "      <td>1.271649</td>\n",
       "      <td>3.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># Sentences</th>\n",
       "      <td>67.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg. Sentence Length</th>\n",
       "      <td>26.58209</td>\n",
       "      <td>315.500000</td>\n",
       "      <td>81.580645</td>\n",
       "      <td>21.549296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      English-Latin1   Hindi-UTF8  Kannada-UTF8  \\\n",
       "Total Words               1781.00000  2524.000000   2529.000000   \n",
       "# Unique Words             533.00000   224.000000    278.000000   \n",
       "Avg. Word Length             4.64402     1.236529      1.271649   \n",
       "# Sentences                 67.00000     8.000000     31.000000   \n",
       "Avg. Sentence Length        26.58209   315.500000     81.580645   \n",
       "\n",
       "                      Hebrew_Ivrit-Hebrew  \n",
       "Total Words                   1530.000000  \n",
       "# Unique Words                 782.000000  \n",
       "Avg. Word Length                 3.960784  \n",
       "# Sentences                     71.000000  \n",
       "Avg. Sentence Length            21.549296  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind = ['Total Words', '# Unique Words', 'Avg. Word Length', '# Sentences', 'Avg. Sentence Length']\n",
    "udhr_stats_df = pd.DataFrame(udhr_stats_dict, index=df_ind)\n",
    "udhr_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Plotting the histograms of sentence lengths for each of the languages using the `sents_len_dict` that we created earlier and looping over all the four languages. We use the matplotlib function `hist()` to plot the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12805e80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,7))\n",
    "for l in lang:\n",
    "    ax.hist(sents_len_dict[l], label=l)\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 (25%). \n",
    "Identify 10 most frequently used words longer than 7 characters in the entire corpus of Inaugural Addresses. Do not identify 10 words for every speech but rather 10 words for the entire corpus. Which among those words has the largest number of synonyms? List all synonyms for those 10 words. Which one of those 10 words has the largest number of hyponyms? List all hyponyms of those 10 most frequently used “long” words. The purpose of this problem is to familiarize you with WordNet and concepts of synonyms and hyponyms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Download the required nltk packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     C:\\Users\\A0687514\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\A0687514\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('inaugural')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Here we loop over all the inaugural speeches file id's and store the words that are longer than 7 characters in a list called `words` using another for loop inside the first one. That way, we have a collection of all the \"long\" words from all the speeches. Next, we create a list of top 10 words using the function `Counter()` from `collections` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaugural_fileids = inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for f in inaugural_fileids:\n",
    "    words_f = inaugural.words(f)\n",
    "    for w in words_f:\n",
    "        if len(w)>7:\n",
    "            words.append(w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = collections.Counter(words)\n",
    "top10_tuples = counter.most_common(10)\n",
    "unzipped = zip(*top10_tuples)\n",
    "top10 = list(list(unzipped)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** \n",
    "Reference: https://www.nltk.org/book/ch02.html\n",
    "\n",
    "Using the `synsets()` function from WordNet dictionary from nltk, we get the set of synonyms which we store in the list called synonyms. Then we do a unique count on each of our 10 most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: government:\n",
      "['administration' 'authorities' 'governance' 'governing' 'government'\n",
      " 'government_activity' 'political_science' 'politics' 'regime']\n",
      "Number of synonyms: 9\n",
      "\n",
      "Word: citizens:\n",
      "['citizen']\n",
      "Number of synonyms: 1\n",
      "\n",
      "Word: constitution:\n",
      "['Constitution' 'Constitution_of_the_United_States' 'Old_Ironsides'\n",
      " 'U.S._Constitution' 'US_Constitution' 'United_States_Constitution'\n",
      " 'composition' 'constitution' 'establishment' 'formation'\n",
      " 'fundamental_law' 'make-up' 'makeup' 'organic_law' 'organisation'\n",
      " 'organization' 'physical_composition']\n",
      "Number of synonyms: 17\n",
      "\n",
      "Word: american:\n",
      "['American' 'American_English' 'American_language']\n",
      "Number of synonyms: 3\n",
      "\n",
      "Word: national:\n",
      "['home' 'interior' 'internal' 'national' 'subject']\n",
      "Number of synonyms: 5\n",
      "\n",
      "Word: congress:\n",
      "['Congress' 'U.S._Congress' 'US_Congress' 'United_States_Congress'\n",
      " 'carnal_knowledge' 'coition' 'coitus' 'congress' 'copulation'\n",
      " 'intercourse' 'relation' 'sex_act' 'sexual_congress' 'sexual_intercourse'\n",
      " 'sexual_relation']\n",
      "Number of synonyms: 15\n",
      "\n",
      "Word: interests:\n",
      "['concern' 'interest' 'interest_group' 'interestingness' 'involvement'\n",
      " 'matter_to' 'occupy' 'pastime' 'pursuit' 'sake' 'stake' 'worry']\n",
      "Number of synonyms: 12\n",
      "\n",
      "Word: political:\n",
      "['political']\n",
      "Number of synonyms: 1\n",
      "\n",
      "Word: executive:\n",
      "['administrator' 'executive' 'executive_director']\n",
      "Number of synonyms: 3\n",
      "\n",
      "Word: principles:\n",
      "['precept' 'principle' 'rationale' 'rule']\n",
      "Number of synonyms: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w in top10:\n",
    "    synonyms = []\n",
    "    for synset in wn.synsets(w):\n",
    "        synonyms = synonyms+synset.lemma_names()\n",
    "    print('Word: %s:'%w) \n",
    "    print(np.unique(synonyms))\n",
    "    syn_count = len(np.unique(synonyms))\n",
    "    print('Number of synonyms: %s\\n'%syn_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** We can see that the word 'constitution' has maximum number of synonyms with the count being 17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** We follow similar looping structure as we did in step 3 here, except that instead of getting the `lemma_names` from `synsets`, we get the `hyponyms()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: government:\n",
      "['Downing_Street' 'ancien_regime' 'authoritarian_regime'\n",
      " 'authoritarian_state' 'bureaucracy' 'court' 'empire' 'federal_government'\n",
      " 'geopolitics' 'government-in-exile' 'lawmaking' 'legislating'\n",
      " 'legislation' 'local_government' 'military_government' 'misgovernment'\n",
      " 'misrule' 'palace' 'papacy' 'pontificate' 'practical_politics'\n",
      " 'pupet_regime' 'puppet_government' 'puppet_state' 'realpolitik'\n",
      " 'royal_court' 'state' 'state_government' 'stratocracy'\n",
      " 'totalitarian_state' 'totalitation_regime' 'trust_busting']\n",
      "Number of hyponyms: 32\n",
      "\n",
      "Word: citizens:\n",
      "['active_citizen' 'civilian' 'elector' 'freeman' 'freewoman'\n",
      " 'private_citizen' 'repatriate' 'thane' 'voter']\n",
      "Number of hyponyms: 9\n",
      "\n",
      "Word: constitution:\n",
      "['collectivisation' 'collectivization' 'colonisation' 'colonization'\n",
      " 'communisation' 'communization' 'federation' 'genetic_constitution'\n",
      " 'genotype' 'grain' 'karyotype' 'phenotype' 'settlement' 'structure'\n",
      " 'texture' 'unionisation' 'unionization']\n",
      "Number of hyponyms: 17\n",
      "\n",
      "Word: american:\n",
      "['AAVE' 'African-American' 'African_American' 'African_American_English'\n",
      " 'African_American_Vernacular_English' 'Afro-American' 'Alabaman'\n",
      " 'Alabamian' 'Alaskan' 'Anglo-American' 'Appalachian' 'Arizonan'\n",
      " 'Arizonian' 'Arkansan' 'Arkansawyer' 'Asian_American' 'Badger'\n",
      " 'Bay_Stater' 'Beaver' 'Black_American' 'Black_English'\n",
      " 'Black_English_Vernacular' 'Black_Vernacular' 'Black_Vernacular_English'\n",
      " 'Bluegrass_Stater' 'Bostonian' 'Buckeye' 'Californian' 'Carolinian'\n",
      " 'Coloradan' 'Connecticuter' 'Cornhusker' 'Creole' 'Delawarean'\n",
      " 'Delawarian' 'Down_Easter' 'Ebonics' 'Floridian' 'Franco-American'\n",
      " 'Garden_Stater' 'Georgian' 'German_American' 'Gopher' 'Granite_Stater'\n",
      " 'Hawaiian' 'Hispanic' 'Hispanic_American' 'Hoosier' 'Idahoan'\n",
      " 'Illinoisan' 'Indianan' 'Iowan' 'Kansan' 'Kentuckian' 'Keystone_Stater'\n",
      " 'Latin_American' 'Latino' 'Louisianan' 'Louisianian' 'Mainer'\n",
      " 'Marylander' 'Mesoamerican' 'Michigander' 'Minnesotan' 'Mississippian'\n",
      " 'Missourian' 'Montanan' 'Nebraskan' 'Nevadan' 'New_Englander'\n",
      " 'New_Hampshirite' 'New_Jerseyan' 'New_Jerseyite' 'New_Mexican'\n",
      " 'New_Yorker' 'Nisei' 'North_American' 'North_Carolinian' 'North_Dakotan'\n",
      " 'Northerner' 'Ohioan' 'Oklahoman' 'Oregonian' 'Pennsylvanian'\n",
      " 'Puerto_Rican' 'Rhode_Islander' 'Sooner' 'South_American'\n",
      " 'South_Carolinian' 'South_Dakotan' 'Southerner' 'Spanish_American'\n",
      " 'Tarheel' 'Tennessean' 'Texan' 'Tory' 'Utahan' 'Vermonter' 'Virginian'\n",
      " 'Volunteer' 'Washingtonian' 'West_Indian' 'West_Virginian' 'Wisconsinite'\n",
      " 'Wolverine' 'Wyomingite' 'Yank' 'Yankee' 'Yankee-Doodle']\n",
      "Number of hyponyms: 109\n",
      "\n",
      "Word: national:\n",
      "['citizen' 'compatriot' 'nationalist' 'patriot']\n",
      "Number of hyponyms: 4\n",
      "\n",
      "Word: congress:\n",
      "['Continental_Congress' 'ass' 'criminal_congress' 'defloration' 'fuck'\n",
      " 'fucking' 'hank_panky' 'nookie' 'nooky' 'penetration' 'piece_of_ass'\n",
      " 'piece_of_tail' 'roll_in_the_hay' 'screw' 'screwing' 'shag' 'shtup'\n",
      " 'unlawful_carnal_knowledge']\n",
      "Number of hyponyms: 18\n",
      "\n",
      "Word: interests:\n",
      "['absorb' 'avocation' 'behalf' 'by-line' 'charisma' 'color' 'colour'\n",
      " 'compound_interest' 'concern' 'controlling_interest' 'engage' 'engross'\n",
      " 'enthusiasm' 'equity' 'fascinate' 'fee' 'grip' 'grubstake' 'hobby'\n",
      " 'insurable_interest' 'intrigue' 'news' 'newsworthiness' 'occupy'\n",
      " 'personal_appeal' 'personal_magnetism' 'pursuit' 'reversion' 'right'\n",
      " 'security_interest' 'shrillness' 'sideline' 'simple_interest'\n",
      " 'spare-time_activity' 'special_interest' 'spellbind'\n",
      " 'terminable_interest' 'topicality' 'transfix' 'undivided_interest'\n",
      " 'undivided_right' 'vested_interest' 'vividness']\n",
      "Number of hyponyms: 43\n",
      "\n",
      "Word: political:\n",
      "[]\n",
      "Number of hyponyms: 0\n",
      "\n",
      "Word: executive:\n",
      "['Bush_administration' 'Carter_administration' 'Clinton_administration'\n",
      " 'DCI' 'Director_of_Central_Intelligence' 'Reagan_administration'\n",
      " 'Secretary_General' 'Surgeon_General' 'V.P.' 'business_executive'\n",
      " 'commissioner' 'corporate_executive' 'government_minister' 'minister'\n",
      " 'prefect' 'rainmaker' 'triumvir' 'vice_president']\n",
      "Number of hyponyms: 18\n",
      "\n",
      "Word: principles:\n",
      "['Gestalt_law_of_organization' 'Gestalt_principle_of_organization'\n",
      " \"Gresham's_Law\" 'Hellenism' \"Huygens'_principle_of_superposition\"\n",
      " \"Le_Chatelier's_law\" \"Le_Chatelier's_principle\"\n",
      " 'Le_Chatelier-Braun_principle' 'Le_Chatelier_principle' \"Naegele's_rule\"\n",
      " \"Occam's_Razor\" \"Ockham's_Razor\" 'Tao' 'accounting_principle'\n",
      " 'accounting_standard' 'basic_principle' 'basics' 'bedrock'\n",
      " 'caveat_emptor' 'chivalry' 'conservation' 'dialectics' 'dictate' 'ethic'\n",
      " 'feng_shui' 'fundamental_principle' 'fundamentals' 'higher_law'\n",
      " 'hypothetical_imperative' 'insurrectionism' 'judicial_doctrine'\n",
      " 'judicial_principle' 'knightliness' 'law_of_parsimony' 'legal_principle'\n",
      " 'localisation' 'localisation_of_function' 'localisation_principle'\n",
      " 'localization' 'localization_of_function' 'localization_principle'\n",
      " 'logic' 'mass-action_principle' 'mass-energy_equivalence' 'mass_action'\n",
      " 'moral_principle' 'pillar' 'pleasure-pain_principle'\n",
      " 'pleasure-unpleasure_principle' 'pleasure_principle'\n",
      " 'principle_of_equivalence' 'principle_of_liquid_displacement'\n",
      " 'principle_of_parsimony' 'principle_of_superposition' 'reality_principle'\n",
      " 'scruple' 'superposition' 'superposition_principle' 'value-system'\n",
      " 'value_orientation' 'yang' 'yin']\n",
      "Number of hyponyms: 62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w in top10:\n",
    "    hyponyms = []\n",
    "    for synset in wn.synsets(w):\n",
    "        for hypo in synset.hyponyms():\n",
    "            for lemma in hypo.lemmas():\n",
    "                hyponyms.append(lemma.name())\n",
    "    print('Word: %s:'%w) \n",
    "    print(np.unique(hyponyms))\n",
    "    hyp_count = len(np.unique(hyponyms))\n",
    "    print('Number of hyponyms: %s\\n'%hyp_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** We can see that the word 'american' has maximum number of synonyms with the count being 109."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3. \n",
    "Consider 100 points along the straight line in $(x,y)$ plane represented by the linear equation $y=0.3x+0.2$. Distribute those points along the line uniformly in the interval between -2.0 and 3.0. To the y coordinate of each point add a random normally distributed value with standard deviation of 1 and mean 0. You have created and artificial set of random measurements. Create a shallow neural network with one layer which will be able to predict y value corresponding to any x value in the above interval. Implement and train the network using Keras API. Report on the accuracy of your model. This is a rather trivial problem and you do not need neural networks to solve it. We are practicing Keras API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Create datasets. We create X using uniform random number generator from numpy library. Then we add the noise to the line $y = 0.3*x + 0.2$ with mean at 0 and standard deviation of 0.1 and call that our y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(low=-2.0, high=3.0, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = 0.3*x + 0.2 \n",
    "noise = np.random.normal(loc=0, scale=0.1, size=100)\n",
    "y = line+noise\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Create train and test data sets using random number generator from numpy library again. 0.7 is the probability, so we basically get a condition which checks if the value is < 0.7 which we store as `mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9001)\n",
    "mask = np.random.rand(100) < 0.7 \n",
    "x_train = x[mask]\n",
    "x_test = x[~mask]\n",
    "y_train = y[mask]\n",
    "y_test = y[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Build the sequential network using `Sequential()` from the `keras` library. Then we add the first dense layer with one node since our y is quantitative. So we only want one output to come out of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0702 20:52:17.786554  8784 deprecation_wrapper.py:119] From C:\\Users\\A0687514\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0702 20:52:17.803554  8784 deprecation_wrapper.py:119] From C:\\Users\\A0687514\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0702 20:52:17.807554  8784 deprecation_wrapper.py:119] From C:\\Users\\A0687514\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Dense(2, input_shape=(1,)))\n",
    "model.add(Dense(1, input_shape=(1,)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Compile and train the model on our data set. We use `SGD` optimizer and `MSE` loss and run it for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0702 20:52:19.261554  8784 deprecation_wrapper.py:119] From C:\\Users\\A0687514\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0702 20:52:19.780554  8784 deprecation_wrapper.py:119] From C:\\Users\\A0687514\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0702 20:52:19.781554  8784 deprecation_wrapper.py:119] From C:\\Users\\A0687514\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 36 samples\n",
      "Epoch 1/50\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.4843 - val_loss: 1.6950\n",
      "Epoch 2/50\n",
      "64/64 [==============================] - 0s 203us/step - loss: 2.7725 - val_loss: 1.0524\n",
      "Epoch 3/50\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.7212 - val_loss: 0.6605\n",
      "Epoch 4/50\n",
      "64/64 [==============================] - 0s 203us/step - loss: 1.0733 - val_loss: 0.4212\n",
      "Epoch 5/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.6774 - val_loss: 0.2754\n",
      "Epoch 6/50\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.4324 - val_loss: 0.1861\n",
      "Epoch 7/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.2818 - val_loss: 0.1312\n",
      "Epoch 8/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.1898 - val_loss: 0.0971\n",
      "Epoch 9/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.1304 - val_loss: 0.0757\n",
      "Epoch 10/50\n",
      "64/64 [==============================] - 0s 391us/step - loss: 0.0937 - val_loss: 0.0619\n",
      "Epoch 11/50\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0704 - val_loss: 0.0528\n",
      "Epoch 12/50\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0554 - val_loss: 0.0466\n",
      "Epoch 13/50\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0455 - val_loss: 0.0421\n",
      "Epoch 14/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0388 - val_loss: 0.0387\n",
      "Epoch 15/50\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0344 - val_loss: 0.0361\n",
      "Epoch 16/50\n",
      "64/64 [==============================] - 0s 687us/step - loss: 0.0307 - val_loss: 0.0339\n",
      "Epoch 17/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0281 - val_loss: 0.0320\n",
      "Epoch 18/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0261 - val_loss: 0.0303\n",
      "Epoch 19/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.0247 - val_loss: 0.0289\n",
      "Epoch 20/50\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0233 - val_loss: 0.0276\n",
      "Epoch 21/50\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0221 - val_loss: 0.0264\n",
      "Epoch 22/50\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0211 - val_loss: 0.0253\n",
      "Epoch 23/50\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0203 - val_loss: 0.0243\n",
      "Epoch 24/50\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0195 - val_loss: 0.0234\n",
      "Epoch 25/50\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0189 - val_loss: 0.0225\n",
      "Epoch 26/50\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0184 - val_loss: 0.0217\n",
      "Epoch 27/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.0177 - val_loss: 0.0210\n",
      "Epoch 28/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.0173 - val_loss: 0.0204\n",
      "Epoch 29/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.0169 - val_loss: 0.0198\n",
      "Epoch 30/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.0165 - val_loss: 0.0193\n",
      "Epoch 31/50\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0161 - val_loss: 0.0188\n",
      "Epoch 32/50\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0158 - val_loss: 0.0183\n",
      "Epoch 33/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0155 - val_loss: 0.0179\n",
      "Epoch 34/50\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0153 - val_loss: 0.0176\n",
      "Epoch 35/50\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0151 - val_loss: 0.0172\n",
      "Epoch 36/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.0148 - val_loss: 0.0169\n",
      "Epoch 37/50\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0147 - val_loss: 0.0166\n",
      "Epoch 38/50\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0145 - val_loss: 0.0163\n",
      "Epoch 39/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 40/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0142 - val_loss: 0.0159\n",
      "Epoch 41/50\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0141 - val_loss: 0.0157\n",
      "Epoch 42/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 43/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0139 - val_loss: 0.0153\n",
      "Epoch 44/50\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0138 - val_loss: 0.0152\n",
      "Epoch 45/50\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0137 - val_loss: 0.0150\n",
      "Epoch 46/50\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 47/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.0136 - val_loss: 0.0148\n",
      "Epoch 48/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 49/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0134 - val_loss: 0.0145\n",
      "Epoch 50/50\n",
      "64/64 [==============================] - 0s 187us/step - loss: 0.0134 - val_loss: 0.0144\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=[x_test, y_test]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** We use `r2_score()` function from `sklearn` library to get the R-squared for the predicted and the true y_test, which we get as ~0.88. That is good, it means we can explain 88% of the variation in our test set using our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8805575353055156"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Here we just plot the true and the predicted y that we get using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x177e4b70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_test, y_test, label='y_true')\n",
    "plt.plot(x_test, y_pred, c='red', label='y_pred')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.  \n",
    "Consider three points in (x,y) plane with coordinates (-2,0), (0,1.7) and (2.1,0). Around each of those three centers create a cloud of 100 randomly generated points. For the radial distance of any one of those points from its center use a random normal distribution.  For the angular coordinate of any one of “cloud” points use the uniform distribution. Once you have generated all three sets of cloud points plot them in the same diagram using three different colors. There should exist some overlap between the clouds. Create a two-layer neural network. Use Keras API. Fit a model that could predict whether a randomly generated point in the plane belongs to cloud 1, centered around (-2,0), cloud 2, centered around (0,1.7) or cloud 3, centered around (2.1,0). You can make that prediction in a much simpler way, however, we are practicing Keras API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Here we generate our three clouds of data points and the respective labels for it. We use the means for these clouds as given in the question and the covariances were adjusted arbitrarily by trial and error to make sure there is some overlap between the clouds as stated in the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A0687514\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\A0687514\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  del sys.path[0]\n",
      "C:\\Users\\A0687514\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "num_points=100\n",
    "\n",
    "# means and covariances\n",
    "mean1 = [-2, 0]\n",
    "mean2 = [0, 1.7]\n",
    "mean3 = [2.1, 0]\n",
    "\n",
    "cov = [[0.7, 0], [0.7, 1]]\n",
    "\n",
    "# cloud 1 samples\n",
    "X1=np.random.multivariate_normal(mean1, cov, num_points)\n",
    "# cloud 2 samples\n",
    "X2=np.random.multivariate_normal(mean2, cov, num_points)\n",
    "# cloud 3 samples\n",
    "X3=np.random.multivariate_normal(mean3, cov, num_points)\n",
    "\n",
    "\n",
    "#cloud 1 labels\n",
    "Y1=0*np.ones(num_points)\n",
    "#cloud 2 labels\n",
    "Y2=1*np.ones(num_points)\n",
    "#cloud 3  labels\n",
    "Y3=2*np.ones(num_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Plot of the three clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cloud 1 \n",
    "plt.scatter(X1[:,0],X1[:,1])\n",
    "#cloud 2 \n",
    "plt.scatter(X2[:,0],X2[:,1])\n",
    "#cloud 3 \n",
    "plt.scatter(X3[:,0],X3[:,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Concatenate our data points and the respective labels in the same order to make sure we map the points and th labels accurately to create one dataset of 300 X's and 300 class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate([X1,X2,X3],axis=0)\n",
    "Y=np.concatenate([Y1,Y2,Y3],axis=0)\n",
    "\n",
    "Y=to_categorical(Y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split( X,Y, test_size=0.2, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Build our network using `Sequential()` again and add two layers each with 3 nodes in the output layer repesenting the three class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 50)                150       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 303\n",
      "Trainable params: 303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(2,)))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Compile and run the model with `Adam()` optimizer, `binary_crossentropy` loss and 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0702 20:52:28.338570  8784 deprecation.py:323] From C:\\Users\\A0687514\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 2.2843 - acc: 0.7778 - val_loss: 2.1682 - val_acc: 0.7944\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 0s 129us/step - loss: 2.0021 - acc: 0.8056 - val_loss: 1.8850 - val_acc: 0.8167\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 0s 121us/step - loss: 1.6504 - acc: 0.7972 - val_loss: 1.1688 - val_acc: 0.8222\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 0s 125us/step - loss: 0.5677 - acc: 0.7944 - val_loss: 0.5191 - val_acc: 0.8333\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 0s 129us/step - loss: 0.2826 - acc: 0.8611 - val_loss: 0.4508 - val_acc: 0.8444\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 0s 121us/step - loss: 0.2861 - acc: 0.8667 - val_loss: 0.4373 - val_acc: 0.8500\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 0s 163us/step - loss: 0.2603 - acc: 0.8556 - val_loss: 0.3572 - val_acc: 0.8500\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 0s 121us/step - loss: 0.2854 - acc: 0.8139 - val_loss: 0.3583 - val_acc: 0.8444\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 0s 129us/step - loss: 0.2839 - acc: 0.8167 - val_loss: 0.3542 - val_acc: 0.8500\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 0s 142us/step - loss: 0.2656 - acc: 0.8250 - val_loss: 0.3474 - val_acc: 0.8500\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.2540 - acc: 0.8361 - val_loss: 0.3416 - val_acc: 0.8444\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 0s 133us/step - loss: 0.2453 - acc: 0.8458 - val_loss: 0.3393 - val_acc: 0.8389\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 0s 146us/step - loss: 0.2268 - acc: 0.8500 - val_loss: 0.3513 - val_acc: 0.8222\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 0s 217us/step - loss: 0.2206 - acc: 0.8528 - val_loss: 0.2625 - val_acc: 0.8333\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 0s 179us/step - loss: 0.2187 - acc: 0.8472 - val_loss: 0.2576 - val_acc: 0.8333\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 0s 183us/step - loss: 0.2206 - acc: 0.8500 - val_loss: 0.2693 - val_acc: 0.8444\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 0s 292us/step - loss: 0.2565 - acc: 0.8236 - val_loss: 0.2727 - val_acc: 0.8389\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 0s 150us/step - loss: 0.2974 - acc: 0.8069 - val_loss: 0.2642 - val_acc: 0.8444\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 0s 208us/step - loss: 0.2375 - acc: 0.8167 - val_loss: 0.2642 - val_acc: 0.8389\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 0s 129us/step - loss: 0.2288 - acc: 0.8306 - val_loss: 0.2653 - val_acc: 0.8167\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=16,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=[x_test, y_test]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** We see that we get a validation accuracy of 0.8833"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
